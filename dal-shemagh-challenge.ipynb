{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":129750,"databundleVersionId":15563344,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":138.657249,"end_time":"2026-02-01T20:17:27.157382","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-02-01T20:15:08.500133","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://i.imgur.com/tzWwJLY.png)","metadata":{"papermill":{"duration":0.003562,"end_time":"2026-02-01T20:15:11.356255","exception":false,"start_time":"2026-02-01T20:15:11.352693","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Competition Baseline - Object Detection + Classification\n\n**Welcome!** This notebook provides a simple YOLOv8 baseline to get you started.\n\n## What this notebook does:\n1. âœ… Loads and prepares the dataset\n2. âœ… Trains a YOLOv8 object detection model\n3. âœ… Generates a valid submission file\n4. âœ… Uses \"-\" for images with no detections (required format)\n\n## Competition Metric:\n**Final Score = 0.5 Ã— mAP@[0.5:0.95] + 0.5 Ã— F1-Score**\n\n---","metadata":{"papermill":{"duration":0.002651,"end_time":"2026-02-01T20:15:11.36162","exception":false,"start_time":"2026-02-01T20:15:11.358969","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Install required packages\n!pip install ultralytics -q","metadata":{"papermill":{"duration":5.934636,"end_time":"2026-02-01T20:15:17.298979","exception":false,"start_time":"2026-02-01T20:15:11.364343","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:31:51.722266Z","iopub.execute_input":"2026-02-11T16:31:51.722546Z","iopub.status.idle":"2026-02-11T16:31:55.219634Z","shell.execute_reply.started":"2026-02-11T16:31:51.722520Z","shell.execute_reply":"2026-02-11T16:31:55.218780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import libraries\nimport os\nimport shutil\nimport pandas as pd\nfrom pathlib import Path\nfrom ultralytics import YOLO\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"papermill":{"duration":12.856377,"end_time":"2026-02-01T20:15:30.158549","exception":false,"start_time":"2026-02-01T20:15:17.302172","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:31:55.221325Z","iopub.execute_input":"2026-02-11T16:31:55.221583Z","iopub.status.idle":"2026-02-11T16:31:59.186446Z","shell.execute_reply.started":"2026-02-11T16:31:55.221553Z","shell.execute_reply":"2026-02-11T16:31:59.185745Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ“ Configuration\nUpdate `ROOT_DIR` to point to your dataset location","metadata":{"papermill":{"duration":0.003015,"end_time":"2026-02-01T20:15:30.164721","exception":false,"start_time":"2026-02-01T20:15:30.161706","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Update this path to match your dataset\nROOT_DIR = \"/kaggle/input/dal-shemagh-detection-challenge\"\nWORK_DIR = \"./yolo_data\"\n\nprint(f\"Dataset directory: {ROOT_DIR}\")\nprint(f\"Working directory: {WORK_DIR}\")","metadata":{"papermill":{"duration":0.009326,"end_time":"2026-02-01T20:15:30.176963","exception":false,"start_time":"2026-02-01T20:15:30.167637","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:31:59.187300Z","iopub.execute_input":"2026-02-11T16:31:59.187662Z","iopub.status.idle":"2026-02-11T16:31:59.192685Z","shell.execute_reply.started":"2026-02-11T16:31:59.187635Z","shell.execute_reply":"2026-02-11T16:31:59.191862Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ“Š Load Data","metadata":{"papermill":{"duration":0.002948,"end_time":"2026-02-01T20:15:30.182924","exception":false,"start_time":"2026-02-01T20:15:30.179976","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load training labels\ntrain_df = pd.read_csv(os.path.join(ROOT_DIR, \"train_labels.csv\"))\nprint(f\"Training images: {len(train_df)}\")\nprint(\"\\nFirst few rows:\")\ndisplay(train_df.head())","metadata":{"papermill":{"duration":0.036268,"end_time":"2026-02-01T20:15:30.222148","exception":false,"start_time":"2026-02-01T20:15:30.18588","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:31:59.193912Z","iopub.execute_input":"2026-02-11T16:31:59.194339Z","iopub.status.idle":"2026-02-11T16:31:59.219586Z","shell.execute_reply.started":"2026-02-11T16:31:59.194296Z","shell.execute_reply":"2026-02-11T16:31:59.218991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## âœ‚ï¸ Train/Validation Split\nSplit data 80/20 with stratification by category","metadata":{"papermill":{"duration":0.003368,"end_time":"2026-02-01T20:15:30.228703","exception":false,"start_time":"2026-02-01T20:15:30.225335","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Split into train (80%) and validation (20%)\ntrain_data, val_data = train_test_split(\n    train_df,\n    test_size=0.2,\n    random_state=42,\n)\n\nprint(f\"Train set: {len(train_data)} images\")\nprint(f\"Validation set: {len(val_data)} images\")","metadata":{"papermill":{"duration":0.015125,"end_time":"2026-02-01T20:15:30.246951","exception":false,"start_time":"2026-02-01T20:15:30.231826","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:31:59.221281Z","iopub.execute_input":"2026-02-11T16:31:59.221670Z","iopub.status.idle":"2026-02-11T16:31:59.229125Z","shell.execute_reply.started":"2026-02-11T16:31:59.221619Z","shell.execute_reply":"2026-02-11T16:31:59.228305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ—‚ï¸ Prepare YOLO Directory Structure\nYOLO expects images and labels in specific folders","metadata":{"papermill":{"duration":0.003394,"end_time":"2026-02-01T20:15:30.253816","exception":false,"start_time":"2026-02-01T20:15:30.250422","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create directories\nfor split in ['train', 'val']:\n    os.makedirs(f\"{WORK_DIR}/images/{split}\", exist_ok=True)\n    os.makedirs(f\"{WORK_DIR}/labels/{split}\", exist_ok=True)\n\ndef prepare_yolo_split(df, split_name):\n    \"\"\"Copy images and labels to YOLO format directories\"\"\"\n    print(f\"\\nPreparing {split_name} set...\")\n    \n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        filename = row['filename']\n        stem = Path(filename).stem\n        \n        # Copy image\n        src_img = os.path.join(ROOT_DIR, \"images/train\", filename)\n        dst_img = os.path.join(WORK_DIR, f\"images/{split_name}\", filename)\n        shutil.copy(src_img, dst_img)\n        \n        # Copy label (create empty if doesn't exist)\n        src_lbl = os.path.join(ROOT_DIR, \"labels/train\", f\"{stem}.txt\")\n        dst_lbl = os.path.join(WORK_DIR, f\"labels/{split_name}\", f\"{stem}.txt\")\n        \n        if os.path.exists(src_lbl):\n            shutil.copy(src_lbl, dst_lbl)\n        else:\n            # Empty label = no objects in image\n            open(dst_lbl, 'w').close()\n\n# Prepare both splits\nprepare_yolo_split(train_data, 'train')\nprepare_yolo_split(val_data, 'val')\n\nprint(\"\\nâœ“ YOLO directories ready!\")","metadata":{"papermill":{"duration":7.02767,"end_time":"2026-02-01T20:15:37.284892","exception":false,"start_time":"2026-02-01T20:15:30.257222","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:31:59.230198Z","iopub.execute_input":"2026-02-11T16:31:59.230855Z","iopub.status.idle":"2026-02-11T16:32:00.816287Z","shell.execute_reply.started":"2026-02-11T16:31:59.230825Z","shell.execute_reply":"2026-02-11T16:32:00.815699Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## âš™ï¸ Create YOLO Configuration","metadata":{"papermill":{"duration":0.006156,"end_time":"2026-02-01T20:15:37.297992","exception":false,"start_time":"2026-02-01T20:15:37.291836","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create data.yaml config file\nyaml_content = f\"\"\"path: {os.path.abspath(WORK_DIR)}\ntrain: images/train\nval: images/val\n\nnc: 2\nnames: ['Face', 'Shemagh']\n\"\"\"\n\nwith open(f\"{WORK_DIR}/data.yaml\", \"w\") as f:\n    f.write(yaml_content)\n\nprint(\"âœ“ Configuration created!\")\nprint(\"\\nContent:\")\nprint(yaml_content)","metadata":{"papermill":{"duration":0.013892,"end_time":"2026-02-01T20:15:37.317908","exception":false,"start_time":"2026-02-01T20:15:37.304016","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:32:00.817259Z","iopub.execute_input":"2026-02-11T16:32:00.817570Z","iopub.status.idle":"2026-02-11T16:32:00.822921Z","shell.execute_reply.started":"2026-02-11T16:32:00.817540Z","shell.execute_reply":"2026-02-11T16:32:00.822259Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸš€ Train YOLO Model\n\nTraining YOLOv8n (nano) - fastest model, good baseline.\n\n**To improve:** Try `yolov8s.pt`, `yolov8m.pt`, or `yolov8l.pt` for better accuracy","metadata":{"papermill":{"duration":0.006174,"end_time":"2026-02-01T20:15:37.330448","exception":false,"start_time":"2026-02-01T20:15:37.324274","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import albumentations as A\n\nimgtransform = A.Compose([\n    # A.Resize((640, 640)),\n    A.HorizontalFlip(p=0.5),\n    A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n    A.GaussianBlur(p=0.1),\n    A.Rotate(limit=10),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:32:00.824003Z","iopub.execute_input":"2026-02-11T16:32:00.824738Z","iopub.status.idle":"2026-02-11T16:32:01.547630Z","shell.execute_reply.started":"2026-02-11T16:32:00.824697Z","shell.execute_reply":"2026-02-11T16:32:01.546805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(\"CUDA Available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:45:12.580219Z","iopub.execute_input":"2026-02-11T16:45:12.580848Z","iopub.status.idle":"2026-02-11T16:45:12.585867Z","shell.execute_reply.started":"2026-02-11T16:45:12.580811Z","shell.execute_reply":"2026-02-11T16:45:12.584949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize model\nmodel = YOLO('yolo11s.pt')\n\nresults = model.train(\n    data=f\"{WORK_DIR}/data.yaml\",\n    epochs=200,\n    imgsz=640,\n    batch=16,\n    patience=50,\n    device = 'cuda' ,\n\n    # LR tuning\n    cos_lr=True,\n    lr0=0.01,\n    lrf=0.01,\n\n    # ---- Augmentations ----\n    hsv_h=0.015,     # color hue jitter\n    hsv_s=0.7,       # saturation jitter\n    hsv_v=0.4,       # brightness jitter\n\n    degrees=5.0,     # small rotations\n    translate=0.10,  # shift\n    scale=0.50,      # zoom in/out\n    shear=2.0,       # shear\n    perspective=0.0005,\n    bgr=0.35, \n\n    fliplr=0.5,      # horizontal flip\n\n    mosaic=1.0,      # strong detection booster\n    mixup=0.90, \n    cutmix = 0.90,\n    copy_paste=0.1,\n    copy_paste_mode = 'mixup',\n\n    close_mosaic=10, # turn off mosaic for last 10 epochs (often improves final quality)\n\n    save=True,\n    plots=True,\n    verbose=True, \n    augmentations = imgtransform,\n)\n\nprint(\"\\nâœ“ Training complete!\")\n","metadata":{"papermill":{"duration":85.576268,"end_time":"2026-02-01T20:17:02.912897","exception":false,"start_time":"2026-02-01T20:15:37.336629","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T16:46:50.526106Z","iopub.execute_input":"2026-02-11T16:46:50.526992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_iou(box1, box2):\n    \"\"\"\n    Calculate IoU between two boxes (x, y, w, h normalized).\n    \"\"\"\n    # Convert from xywh to x1, y1, x2, y2\n    b1_x1, b1_x2 = box1[0] - box1[2]/2, box1[0] + box1[2]/2\n    b1_y1, b1_y2 = box1[1] - box1[3]/2, box1[1] + box1[3]/2\n    \n    b2_x1, b2_x2 = box2[0] - box2[2]/2, box2[0] + box2[2]/2\n    b2_y1, b2_y2 = box2[1] - box2[3]/2, box2[1] + box2[3]/2\n\n    # Intersection coordinates\n    inter_x1 = max(b1_x1, b2_x1)\n    inter_y1 = max(b1_y1, b2_y1)\n    inter_x2 = min(b1_x2, b2_x2)\n    inter_y2 = min(b1_y2, b2_y2)\n\n    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n    \n    union_area = b1_area + b2_area - inter_area\n    return inter_area / union_area if union_area > 0 else 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:38:45.443727Z","iopub.execute_input":"2026-02-11T17:38:45.444558Z","iopub.status.idle":"2026-02-11T17:38:45.450669Z","shell.execute_reply.started":"2026-02-11T17:38:45.444519Z","shell.execute_reply":"2026-02-11T17:38:45.449841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ“ˆ Validate Model","metadata":{"papermill":{"duration":0.022515,"end_time":"2026-02-01T20:17:02.959149","exception":false,"start_time":"2026-02-01T20:17:02.936634","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Evaluate on validation set\nmetrics = model.val()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"VALIDATION RESULTS\")\nprint(\"=\"*60)\nprint(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")\nprint(f\"mAP@0.5:     {metrics.box.map50:.4f}\")\nprint(f\"mAP@0.75:    {metrics.box.map75:.4f}\")\nprint(\"=\"*60)","metadata":{"papermill":{"duration":4.35128,"end_time":"2026-02-01T20:17:07.333087","exception":false,"start_time":"2026-02-01T20:17:02.981807","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:38:45.451736Z","iopub.execute_input":"2026-02-11T17:38:45.451980Z","iopub.status.idle":"2026-02-11T17:38:50.492327Z","shell.execute_reply.started":"2026-02-11T17:38:45.451939Z","shell.execute_reply":"2026-02-11T17:38:50.491245Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ”® Generate Submission\n\nRun inference on test set and create submission file","metadata":{"papermill":{"duration":0.023316,"end_time":"2026-02-01T20:17:07.38023","exception":false,"start_time":"2026-02-01T20:17:07.356914","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"Generating submission file...\\n\")\n\ntest_img_dir = os.path.join(ROOT_DIR, \"images/test\")\nsubmission_rows = []\n\n# ===== DEBUG TOGGLES =====\nDEBUG_PRINT = True\nDEBUG_VIS   = True\nDEBUG_N     = None\n# =========================\n\ntest_images = sorted([f for f in os.listdir(test_img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\nprint(f\"Found {len(test_images)} test images\\n\")\n\nfor idx, filename in enumerate(tqdm(test_images, desc=\"Inference\")):\n    img_path = os.path.join(test_img_dir, filename)\n    \n    results = model.predict(\n        source=img_path,\n        device = 0,\n        conf=0.15,\n        iou=0.8,\n        verbose=False\n    )[0]\n\n    pred_parts = []\n    person_boxes = []\n    shemagh_boxes = []\n\n    if len(results.boxes) == 0:\n        prediction_string = \"-\"\n        right_place = 0\n    else:\n        for box in results.boxes:\n            cls = int(box.cls[0])\n            conf = float(box.conf[0])\n            x, y, w, h = box.xywhn[0].tolist()\n\n            pred_parts.append(f\"{cls} {conf:.4f} {x:.4f} {y:.4f} {w:.4f} {h:.4f}\")\n\n            if cls == 0:\n                person_boxes.append([x, y, w, h])\n            elif cls == 1:\n                shemagh_boxes.append([x, y, w, h])\n\n        prediction_string = \" \".join(pred_parts)\n        right_place = 0\n\n        if person_boxes and shemagh_boxes:\n            for s_box in shemagh_boxes:\n                for p_box in person_boxes:\n                    iou = calculate_iou(s_box, p_box)\n                    if iou > 0.1:\n                        right_place = 1\n                        break\n                if right_place == 1:\n                    break\n\n\n    if DEBUG_PRINT and (DEBUG_N is None or idx < DEBUG_N):\n        print(f\"\\nImage: {filename}\")\n        print(f\"Right Place: {right_place}\")\n    \n        if prediction_string == \"-\":\n            print(\"No detections\")\n        else:\n            for part in pred_parts:\n                print(part)\n    \n    # ===== DEBUG VISUALIZATION =====\n    if DEBUG_VIS and (DEBUG_N is None or idx < DEBUG_N):\n        import cv2\n        import matplotlib.pyplot as plt\n    \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n        for box in results.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0])\n            cls = int(box.cls[0])\n            conf = float(box.conf[0])\n    \n            label = f\"{cls}:{conf:.2f}\"\n            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n            cv2.putText(\n                img, label, (x1, max(0, y1 - 8)),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2\n            )\n    plt.figure(figsize=(7, 7))\n    plt.title(f\"{filename} | Right Place: {right_place}\")\n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.show()\n    # ==========================================\n\n    submission_rows.append({\n        \"filename\": filename,\n        \"right_place\": right_place,\n        \"prediction_string\": prediction_string\n    })\n\nsubmission = pd.DataFrame(submission_rows)\n\nprint(\"\\nâœ“ Submission generated!\")\nprint(f\"Total rows: {len(submission)}\")\nprint(f\"With detections: {(submission['prediction_string'] != '-').sum()}\")\nprint(f\"Without detections: {(submission['prediction_string'] == '-').sum()}\")\n","metadata":{"papermill":{"duration":16.517232,"end_time":"2026-02-01T20:17:23.920737","exception":false,"start_time":"2026-02-01T20:17:07.403505","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:45:40.465951Z","iopub.execute_input":"2026-02-11T17:45:40.466619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx, filename in enumerate(tqdm(test_images, desc=\"Inference\")):\n    img_path = os.path.join(test_img_dir, filename)\n\n    if DEBUG_PRINT and (DEBUG_N is None or idx < DEBUG_N):\n        print(f\"\\nImage: {filename}\")\n        print(f\"Right Place: {right_place}\")\n    \n        if prediction_string == \"-\":\n            print(\"No detections\")\n        else:\n            for part in pred_parts:\n                print(part)\n    \n    # ===== DEBUG VISUALIZATION =====\n    if DEBUG_VIS and (DEBUG_N is None or idx < DEBUG_N):\n        import cv2\n        import matplotlib.pyplot as plt\n    \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n        for box in results.boxes:\n            x1, y1, x2, y2 = map(int, box.xyxy[0])\n            cls = int(box.cls[0])\n            conf = float(box.conf[0])\n    \n            label = f\"{cls}:{conf:.2f}\"\n            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n            cv2.putText(\n                img, label, (x1, max(0, y1 - 8)),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2\n            )\n    plt.figure(figsize=(7, 7))\n    plt.title(f\"{filename} | Right Place: {right_place}\")\n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:41:24.535210Z","iopub.execute_input":"2026-02-11T17:41:24.535910Z","iopub.status.idle":"2026-02-11T17:41:38.310647Z","shell.execute_reply.started":"2026-02-11T17:41:24.535875Z","shell.execute_reply":"2026-02-11T17:41:38.309605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport cv2\nimport matplotlib.pyplot as plt\n\nlowest_preds.sort(key=lambda x: x[0])  # lowest score first\n\nN = 50  # change to show more/less\nprint(f\"\\nShowing {N} lowest-confidence images...\")\n\nfor score, img_path, results in lowest_preds[:N]:\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    # draw boxes\n    for box in results.boxes:\n        x1, y1, x2, y2 = map(int, box.xyxy[0])\n        conf = float(box.conf[0])\n        cls = int(box.cls[0])\n\n        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n        cv2.putText(\n            img,\n            f\"{cls}:{conf:.2f}\",\n            (x1, max(0, y1 - 8)),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            0.6,\n            (255, 0, 0),\n            2\n        )\n\n    plt.figure(figsize=(7, 7))\n    plt.title(f\"{os.path.basename(img_path)} | lowest_conf={score:.3f}\")\n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:39:04.207787Z","iopub.execute_input":"2026-02-11T17:39:04.208036Z","iopub.status.idle":"2026-02-11T17:39:04.217032Z","shell.execute_reply.started":"2026-02-11T17:39:04.208010Z","shell.execute_reply":"2026-02-11T17:39:04.216111Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ’¾ Save Submission","metadata":{"papermill":{"duration":0.028322,"end_time":"2026-02-01T20:17:23.978198","exception":false,"start_time":"2026-02-01T20:17:23.949876","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save to CSV\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ“ SUBMISSION SAVED: submission.csv\")\nprint(\"=\"*60)\nprint(\"\\nFirst 10 rows:\")\ndisplay(submission.head(10))","metadata":{"papermill":{"duration":0.046873,"end_time":"2026-02-01T20:17:24.053219","exception":false,"start_time":"2026-02-01T20:17:24.006346","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:39:04.217534Z","iopub.status.idle":"2026-02-11T17:39:04.218257Z","shell.execute_reply.started":"2026-02-11T17:39:04.218034Z","shell.execute_reply":"2026-02-11T17:39:04.218071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## ðŸŽ¯ Next Steps\n\nThis baseline gives you a working submission. To improve your score:\n\n1. **Add Augmentations** - Try to add augmentations\n2. **Use larger model** - Try `yolov8s.pt` or `yolov8m.pt`\n3. **Train longer** - Increase epochs to 100-200\n4. **Add classification model** - Build a model for `right_place` instead of always using 0 (or maybe think about a more elegant way to predict it!)\n\n---\n\nGood luck! ðŸ€","metadata":{"papermill":{"duration":0.028534,"end_time":"2026-02-01T20:17:24.111199","exception":false,"start_time":"2026-02-01T20:17:24.082665","status":"completed"},"tags":[]}}]}